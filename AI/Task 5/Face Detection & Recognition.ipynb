{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T14:48:33.236028Z",
     "start_time": "2024-12-10T14:48:31.121773Z"
    }
   },
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:48:34.590167Z",
     "start_time": "2024-12-10T14:48:34.586795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Global variables\n",
    "known_faces = []\n",
    "known_names = []\n",
    "exit_flag = False  # Global exit flag\n"
   ],
   "id": "3e1dcb357f6f0e61",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:00:58.236571Z",
     "start_time": "2024-12-10T15:00:58.228637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_and_recognize_faces(video_source=0, window_name=\"Face Detection and Recognition\", width=800, height=600, resize_factor=0.5, frame_skip=2):\n",
    "    \"\"\"\n",
    "    Optimized face detection and recognition for faster video processing.\n",
    "\n",
    "    :param video_source: Index of the video source (default: 0 for webcam) or path to a video file.\n",
    "    :param window_name: Name of the OpenCV window.\n",
    "    :param width: Width of the display window.\n",
    "    :param height: Height of the display window.\n",
    "    :param resize_factor: Factor by which to downscale the frames for faster processing (default: 0.5).\n",
    "    :param frame_skip: Number of frames to skip between processing (default: 2).\n",
    "    \"\"\"\n",
    "    global exit_flag\n",
    "    exit_flag = False  # Reset the flag when the function starts\n",
    "\n",
    "    # Create a named window and set its size\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, width, height)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_source)\n",
    "\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to exit the video stream.\")\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        if exit_flag:  # Checking exit flag\n",
    "            break\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"End of video or failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Skip frames for faster processing\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # Resize the frame\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            name = \"Unknown\"\n",
    "            if known_faces:\n",
    "                # Compare face encoding to known faces\n",
    "                matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "                face_distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_names[best_match_index]\n",
    "\n",
    "            # Scale the face location back to the original frame size\n",
    "            top = int(top / resize_factor)\n",
    "            right = int(right / resize_factor)\n",
    "            bottom = int(bottom / resize_factor)\n",
    "            left = int(left / resize_factor)\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # Display frame\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Exit when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "193116ae8a795ab6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:01:00.732722Z",
     "start_time": "2024-12-10T15:01:00.728828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_known_face(image_path, name):\n",
    "    \"\"\"\n",
    "    Add a known face to the database.\n",
    "    :param image_path: Path to the image file.\n",
    "    :param name: Name of the person in the image.\n",
    "    \"\"\"\n",
    "    global known_faces, known_names\n",
    "\n",
    "    # Load the image\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "    if face_encodings:\n",
    "        # Add face encoding and name to the lists\n",
    "        known_faces.append(face_encodings[0])\n",
    "        known_names.append(name)\n",
    "        print(f\"Added {name} to known faces.\")\n",
    "    else:\n",
    "        print(\"No face detected in the image. Please try again.\")\n",
    "\n",
    "\n",
    "#add_known_face(\"path/to/image.jpg\", \"Person Name\")\n"
   ],
   "id": "491921117e0120a9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:01:02.331855Z",
     "start_time": "2024-12-10T15:01:02.328127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exit_video():\n",
    "    \"\"\"\n",
    "    Sets the exit flag to terminate video capture.\n",
    "    \"\"\"\n",
    "    global exit_flag\n",
    "    exit_flag = True\n",
    "    print(\"Exit signal received. Closing video stream.\")\n"
   ],
   "id": "1b3b2c2deff5ae14",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:01:14.099794Z",
     "start_time": "2024-12-10T15:01:03.577654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "        #            To detect faces using the webcam\n",
    "#                                detect_and_recognize_faces(0, width=1280, height=720)\n",
    "\n",
    "#            To detect faces in a video file\n",
    "#                               Replace 'path/to/video.mp4' with the actual path to the video file\n",
    "detect_and_recognize_faces(\"D:/Work,Courses & Studies/Yomna - edits & Work/CodSoft_Tasks/AI/Task 5/test.mp4\",  resize_factor=0.6, frame_skip=2)\n"
   ],
   "id": "f59a2d626cfb2b55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit the video stream.\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
